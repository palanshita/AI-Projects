# -*- coding: utf-8 -*-
"""final-tsr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1npkSneNWfTnvfIsOAbgq8nf_c0oNhOTg
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import os
import cv2
import pathlib
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from sklearn.model_selection import train_test_split

import warnings
warnings.filterwarnings("ignore")

from google.colab import files
files.upload()

!pip install kaggle
!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign

!ls -lh

!unzip gtsrb-german-traffic-sign.zip -d traffic_signs

data_dir = "/content/traffic_signs"  # Update if needed

# Get all file paths in the dataset
all_files = []
for root, _, files in os.walk(data_dir):
    for file in files:
        file_path = os.path.join(root, file)
        all_files.append(file_path)

# Display total number of files and a few examples
print("Total files found:", len(all_files))
print(all_files[:5])  # Print first 5 file paths

train_csv = pd.read_csv("/content/traffic_signs/Train.csv")  # Adjust the path if necessary

# Extract only 'Path' and 'ClassId' columns
train_data = train_csv[['Path', 'ClassId']]

print(train_data.head())

X, y = [], []
for i, row in train_data.iterrows():
    img_path = os.path.join(data_dir, row['Path'])
    image = cv2.imread(img_path)
    image = cv2.resize(image, (32, 32))  # Resize to 32x32
    X.append(image)
    y.append(row['ClassId'])

X = np.array(X) / 255.0  # Normalize images

from tensorflow.keras.utils import to_categorical

y = to_categorical(y)   # It one-hot encodes class labels.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("Data Split Done! Train Shape:", X_train.shape, "Test Shape:", X_test.shape)

# Data Augmentation
datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.15, width_shift_range=0.1, height_shift_range=0.1)

NUM_CATEGORIES = 43  # Number of classes
IMG_WIDTH, IMG_HEIGHT = 32, 32
train_path = os.path.join(data_dir, "Train")
img_dir = pathlib.Path(train_path)
plt.figure(figsize=(14, 14))
for i in range(NUM_CATEGORIES):
    plt.subplot(7, 7, i+1)
    sign = list(img_dir.glob(f'{i}/*'))[0]
    img = load_img(sign, target_size=(IMG_WIDTH, IMG_HEIGHT))
    plt.imshow(img)
plt.show()

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(43, activation='softmax')  # 43 classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=15)

# flow() works with NumPy arrays

# Evaluate Model
loss, acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {acc*100:.2f}%")

# Plot Training History
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.legend()
plt.title('Model Accuracy')

plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('Model Loss')
plt.show()

# Predict Sample Images
def predict_sample_images():
    fig, axes = plt.subplots(3, 5 , figsize=(12, 8))
    for i, ax in enumerate(axes.flat):
        img = X_test[i]
        true_label = np.argmax(y_test[i])
        pred_label = np.argmax(model.predict(img.reshape(1, 32, 32, 3)))
        ax.imshow(img)
        ax.set_title(f"Pred: {pred_label} | True: {true_label}")
        ax.axis('off')
    plt.show()

predict_sample_images()

# Save the trained model
model.save("traffic_sign_model.h5")

from tensorflow.keras.models import load_model

from PIL import Image  # Import the Image module from Pillow
import numpy as np
import cv2
from tensorflow.keras.models import load_model
from google.colab import files

# Upload an image
uploaded = files.upload()
image_path = list(uploaded.keys())[0]  # Get the uploaded file name

# Load the trained model
model = load_model("traffic_sign_model.h5")  # Ensure the correct model file is loaded

# Load the class names (modify with your actual mapping)
class_labels = {
    0: "Speed Limit (20km/h)", 1: "Speed Limit (30km/h)", 2: "Speed Limit (50km/h)",
    3: "Speed Limit (60km/h)", 4: "Speed Limit (70km/h)", 5: "Speed Limit (80km/h)",
    6: "End of Speed Limit (80km/h)", 7: "Speed Limit (100km/h)", 8: "Speed Limit (120km/h)",
    9: "No Passing", 10: "No Passing for Vehicles over 3.5 tons",
    11: "Right-of-Way at Intersection", 12: "Priority Road",
    13: "Yield", 14: "Stop", 15: "No Vehicles",
    16: "Vehicles over 3.5 tons Prohibited", 17: "No Entry",
    18: "General Caution", 19: "Dangerous Curve Left",
    20: "Dangerous Curve Right", 21: "Double Curve",
    22: "Bumpy Road", 23: "Slippery Road",
    24: "Road Narrows on the Right", 25: "Road Work",
    26: "Traffic Signals", 27: "Pedestrians",
    28: "Children Crossing", 29: "Bicycles Crossing",
    30: "Beware of Ice/Snow", 31: "Wild Animals Crossing",
    32: "End of All Speed and Passing Limits", 33: "Turn Right Ahead",
    34: "Turn Left Ahead", 35: "Ahead Only",
    36: "Go Straight or Right", 37: "Go Straight or Left",
    38: "Keep Right", 39: "Keep Left",
    40: "Roundabout Mandatory", 41: "End of No Passing",
    42: "End of No Passing for Vehicles over 3.5 tons"
}

# Function to preprocess and predict the class of an image
def predict_traffic_sign(model, image_path):
    # Load image
    img = Image.open(image_path).convert('RGB')
    img = img.resize((32, 32))  # Resize to match model input
    img = np.array(img)  # Convert to numpy array

    # Ensure correct color channel ordering
    if img.shape[-1] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

    img = img / 255.0  # Normalize (same as training)
    img = np.expand_dims(img, axis=0)  # Add batch dimension

    # Predict class
    prediction = model.predict(img)
    class_id = np.argmax(prediction)  # Get the predicted class
    confidence = np.max(prediction)  # Get confidence score

    return class_id, confidence

# Test with an uploaded image
predicted_class, confidence = predict_traffic_sign(model, image_path)

# Print the predicted class
print(f"Predicted Traffic Sign: {class_labels.get(predicted_class, 'Unknown')}")
print(f"Confidence Score: {confidence:.2f}")

import matplotlib.pyplot as plt
plt.imshow(Image.open(image_path))
plt.title("Uploaded Image")
plt.axis("off")
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Fix one-hot encoded y_test if needed
if y_test.ndim == 2 and y_test.shape[1] == 43:
    y_test_labels = np.argmax(y_test, axis=1)
else:
    y_test_labels = y_test  # already in label form

# Get predicted class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate per-class accuracy
num_classes = len(class_labels)
class_accuracies = {}

for class_id in range(num_classes):
    indices = np.where(y_test_labels == class_id)[0]
    if len(indices) == 0:
        class_accuracies[class_id] = 0
        continue
    correct_preds = np.sum(y_pred_classes[indices] == y_test_labels[indices])
    accuracy = correct_preds / len(indices)
    class_accuracies[class_id] = accuracy

# Plot
plt.figure(figsize=(14, 8))
plt.bar(range(num_classes), [class_accuracies[i] for i in range(num_classes)], color='cornflowerblue')
plt.xticks(range(num_classes), [class_labels[i] for i in range(num_classes)], rotation=90)
plt.ylabel('Accuracy')
plt.title('Per-Class Accuracy on Test Set')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

